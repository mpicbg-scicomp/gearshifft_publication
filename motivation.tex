A FFT is a fast implementation of the discrete Fourier transform which is a standard text-book mathematical procedure. The forward transform is a mapping from an array $x$ of $n$ complex numbers in the time domain to an array $X$ of $n$ complex numbers in the frequency domain (also referred to as Fourier domain):

\begin{equation}
  \label{eq:dft}
  X[k] = \sum_{j=0}^{n-1} x[j]e^{\frac{-2\pi\sqrt{-1}jk}{n}}
\end{equation}

with $k$ being an integer index within $0 \le k < n$. This operation was found to be computable in $\mathcal{O}(n \log n)$ complexity by Cooley-Turkey \cite{cooley1965algorithm}, which in turn rediscovered findings by Gauss \cite{gauss}. The basis for this solution is the observation that, given the factorization of $n=n_1n_2$, the  DFT of size $n$ can be rewritten by smaller DFTs of size $n_1$ and $n_2$.  Given the aforementioned indices $j=j_1n_2 + j_2$ and $k=k_1+k_2n_1$, \cref{eq:dft} can be re-expressed as:

\begin{equation}
  \label{eq:cooley-turkey}
  X[k_1 + k_2n_1] = \sum_{j_2=0}^{n_2-1} \left( \left( \sum_{j_1=0}^{n_1-1} x[j_1n_2 + j_2] e^{\frac{-2\pi\sqrt{-1}j_1k_1}{n_1}} \right) e^{\frac{-2\pi\sqrt{-1}j_2k_1}{n}} \right) e^{\frac{-2\pi\sqrt{-1}j_2k_2}{n_2}}
\end{equation}

Equation \cref{eq:cooley-turkey} describes a decomposition that can be performed recursively. Here, $n_1$ would be denoted as \emph{radix} which refers to $n_1$ transforms of size $n_2$. These smaller transforms are combined by a \emph{butterfly} pattern with $n_2$ DFTs of size $n_1$ on the outputs of the corresponding sub-transforms.
For $n$ being a power of two, the radix-2 DFT is rather simple and a common implemented form of Cooley-Tukey algorithm \cite{cooley1965algorithm}.
Arbitrary and mixed radices are more complicated and can be tackled with the prime-factorization or Chirp Z-transform implemented by the Bluestein's algorithm \cite{bluestein}.
Due to these differences, we classify the FFT extent shapes into \emph{powerof2} (radix-2), \emph{radix357} (mixed-radix of primes 3, 5 and 7) and into \emph{oddshape} (arbitrary radices excluding the previous cases).
This mathematical discussion has essential consequences for the design and implementation of libraries that perform FFTs in various hardware environments, which shall become evident later.

Every developer in the scientific arena or other domains that perform heavy computations expects that the performance of the FFT implementation in his or her preferred language meets the standards of the acronym, i.e. it is fast or even the fastest available. As discussed in \cref{sec:intro}, the landscape of available implementations on various hardware platforms has become very diverse. Keeping a clear view of performance that can be expected of FFT implementations is becoming a challenge. 

With \gearshifft{}, our aim is to provide a set of simple commands to the community to run benchmarks against their desired FFT implementation and compare to other implementations in an unbiased way. Given the high rate of updates to e.g. GPU based FFT implementations (cuFFT experiences around 1-2 release updates per year with every CUDA version, clfft was updated six times during the course of 2016) library vendors need to assess if the most recent version of their used FFT implementation yields the performance profits to justify updating their own packages or bindings thereof. Further more, new users are often overwhelmed by the number of different FFT implementations and their variations in use. Also, HPC cluster administrators that would like to offer the best performing software stack to their users do also feel the need to stay on top of the developments. 

For this purpose, \gearshifft{} approaches the challenge of benchmarking a variety of FFT libraries from a user perspective. This means, that the following parameters shall be easy to study:

\begin{enumerate}
\item input data dimension and shape, i.e. whether 1D, 2D or 3D input data
\item transform data, i.e. real to complex numbers or from complex to complex numbers
\item transform precision, i.e. 32-bit or 64-bit IEEE floating point number representation
\item memory mode (``placeness'')
  \begin{itemize}
  \item \emph{in-place}: the input data structure is used for storing the output data (low memory footprint and low bandwidth are to be expected)
  \item \emph{out-of-place}:  where the transformed input is written to a different memory location than where the input resides (high memory footprint and high bandwidth are to be expected)
  \end{itemize}
\item transform direction, i.e. forward (from discrete space to frequency space) or backward (from frequency space to discrete space)
\end{enumerate}
 
Last but not least, \gearshifft{} was primarily design to study and compare the performance of GPU accelerators running FFT implementations versus classical CPU based FFT libraries.   
