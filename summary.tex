
With this paper, we present \gearshifft{} to the HPC community and other performance enthusiasts as an open-source, vendor-independent and free FFT benchmark suite for heterogeneous platforms. \gearshifft{} is a C++14 modular benchmark code that allows to perform forward and backward FFT transforms on various types of input data (both in shape, memory organization, precision and data type). \gearshifft{}'s design offers an extensible architecture to accommodate FFT packages with low overhead. The hallmark of \gearshifft{} is to produce reliable benchmark data that can easily be consumed by external software for visualization and for easier reproducibility. By these design choices, we hope that \gearshifft{} appeals to both FFT practitioners, FFT library developers, HPC admins or integrators and decision makers for a wide range of use cases. To showcase these capabilities, we presented a first study of common urban myths for using 3 state of the art FFT libraries, \fftw{}, \clfft{} and \cufft{}. We were able to show that the time consumed for the creation of \fftw{} plans can have non-negligible contributions to the time to solution which users of \fftw{} should be aware of. Furthermore, we compared the performance of CPU based implementations Haswell Xeon CPUs to state-of-the-art Pascal generation \nvidia{} GPUs. We were able to show that for input signal sizes of less than \SI{1}{\mebi\byte}, the CPU implementation is superior whereas for larger input data size the GPU offers better turn-around. The difference between runtimes of power-of-2, {\tt radix357} and power-of-19 shaped input data was demonstrated to be negligible for \fftw{} and non-negligible for \cufft{} transforms used in this study. We were also able to identify runtime differences when using complex versus real arrays and when comparing double versus single precision data types.     

As we warmly welcome contributions of benchmarks from various pieces of hardware, we hope to extend the \gearshifft{} repository with many more data sets of platforms used in the HPC arena of today and tomorrow. We are planning on running \gearshifft{} on non-x86 hardware to establish a basis for hardware performance comparisons. Connected to this, we plan to explore more state-of-the-art FFT libraries such as Intel IPPS, Intel MKL, AMD's rocFFT etc. We would also like to consolidate the benchmark data structure, so that many more analyses are possible than were presented in this paper both in terms of performance exploration as well as energy consumption.  

\paragraph{Acknowledgments.} The work of Matthias Werner was funded by \nvidia{} through the GPU Center of Excellence (GCOE) at the Center for Information Services and High Performance Computing (ZIH), TU Dresden, where the K20Xm and K80 GPU cluster Taurus was used. We would like to thank the Helmholtz-Zentrum Dresden-Rossendorf for providing the infrastructure to host the \nvidia{} Tesla P100 (provided by \nvidia{} for the GCOE) in the Hypnos HPC cluster. We would also like to thank the Max Planck Institute of Molecular Cell Biology and Genetics for supporting this publication by providing computing infrastructure and service staff working time.
