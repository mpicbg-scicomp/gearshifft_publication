
With this paper \gearshifft{} is presented to the HPC community and other performance enthusiasts as an open-source, vendor-independent and free FFT benchmark suite for heterogeneous platforms. \gearshifft{} is a C++14 modular benchmark code that allows to perform forward and backward FFT transforms on various types of input data (both in shape, memory organization, precision and data type). \gearshifft{}'s design offers an extensible architecture to accommodate FFT packages with low overhead. \gearshifft{}'s design choices addresses both FFT practitioners, FFT library developers, HPC admins or integrators and decision makers supporting a wide range of use cases. 

To showcase the capabilities of \gearshifft{}, a first study of three common FFT libraries, \fftw{}, \clfft{} and \cufft{} is presented. The performance of CPU based implementations Haswell Xeon CPUs to state-of-the-art Pascal generation \nvidia{} GPUs is compared. The results indicate that for input signal sizes of less than \SI{1}{\mebi\byte}, the CPU implementation is superior whereas for larger input data size the GPU offers better turn-around. The difference between runtimes of \texttt{powerof2}, \texttt{radix357} and power-of-19 shaped input data was demonstrated to be negligible for \fftw{} and non-negligible for \cufft{} transforms used in this study. The results further indicate runtime differences when using complex versus real arrays and when comparing double versus single precision data types.     

As we warmly welcome contributions of benchmarks from various pieces of hardware, we hope to extend the \gearshifft{} repository with many more data sets of platforms used in the HPC arena of today and tomorrow. It is planned to run \gearshifft{} on non-x86 hardware to establish a basis for hardware performance comparisons. Connected to this, we plan to explore more state-of-the-art FFT libraries such as Intel IPPS, Intel MKL, AMD's rocFFT, cusFFT etc. It is a future task to consolidate the benchmark data structure and to open another benchmark paths for e.g. FFT callbacks, so that many more analyses are possible than were presented in this paper both in terms of performance exploration as well as energy consumption.

\paragraph{Acknowledgments.} The work was funded by \nvidia{} through the GPU Center of Excellence (GCOE) at the Center for Information Services and High Performance Computing (ZIH), TU Dresden, where the K20Xm and K80 GPU cluster Taurus was used. We would like to thank the Helmholtz-Zentrum Dresden-Rossendorf for providing the infrastructure to host the \nvidia{} Tesla P100 (provided by \nvidia{} for the GCOE) in the Hypnos HPC cluster. We would also like to thank the Max Planck Institute of Molecular Cell Biology and Genetics for supporting this publication by providing computing infrastructure and service staff working time.
